{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/intanmire/Complete-Deep-Learning/blob/master/riset1_covid_19_x_ray_images_eda_models_(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlhnMrch9Yzl"
      },
      "source": [
        "## COVID-19 Classifier from X-Ray Images\n",
        "\n",
        "#### Tasks\n",
        "\n",
        "- [✔️] Exploratory Data Analysis\n",
        "- [✔️] Image augumentation\n",
        "- [✔️] Base CNN model accuracy calculation\n",
        "- [✔️] Base CNN model with lower imbalance data\n",
        "- [✔️] RESNET 50 model accuracy calculation\n",
        "- [✔️] EfficientNet B4 accuracy calculation\n",
        "- [✔️] AUC Score comparision\n",
        "- [⚫] Results\n",
        "\n",
        "#### Version Information\n",
        "\n",
        "- v1 :\n",
        "    - Completed exploratory data analysis of given metadata\n",
        "    - Completed exploratory data analysis of provided images\n",
        "    - Inferences of both EDA explained\n",
        "\n",
        "- v2 :\n",
        "    - Code cleaning\n",
        "    - Output cleaning\n",
        "\n",
        "- v3 :\n",
        "    - Completed Image Augumentation using Keras ImageDataGenerator\n",
        "    - Completed training of base CNN model on data\n",
        "    - Accuracy inference of base CNN model completed\n",
        "    \n",
        "- v4 :\n",
        "    - Trained base CNN model on balanced data\n",
        "    - Inferenced accuracy of base CNN model on balanced data\n",
        "    - Trained ResNet 50 model on data\n",
        "    - Inferenced accuracy of ResNet 50 model\n",
        "    \n",
        "- v5 :\n",
        "    - Because of severe class imbalance, metric for model training and validation is changed from accuracy -> AUC ROC\n",
        "    - [Really Good Article on choosing evaluation metrics](https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/)\n",
        "    - Trained EfficientNet B4 model on data\n",
        "    - Inferenced accuracy of EfficientNet B4 model\n",
        "    - AUC score comparisions of all trained models\n",
        "    \n",
        "- v6 :\n",
        "    - Added multiple metrics for better view of model comparison\n",
        "    - Added numpy and tensorflow seeding for reproducible results\n",
        "\n",
        "- v7 :\n",
        "    - Code cleaning, debugging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "Xh0MgCvH9fh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "6fw5nNroz-uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "FOqnUs8p0Hfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "sfcHuHH89Yzv"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "# v1\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# v3\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.metrics import *\n",
        "# v4\n",
        "\n",
        "ACCURACY_LIST = []\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.models import Model\n",
        "\n",
        "# v5\n",
        "#!pip install efficientnet\n",
        "from tensorflow.keras import applications\n",
        "from keras.applications.efficientnet import EfficientNetB4\n",
        "from keras import backend as K\n",
        "\n",
        "# v6\n",
        "# Get reproducible results\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5qkGEHs9Yzz"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "metadata = pd.read_csv('/kaggle/input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv')\n",
        "summary = pd.read_csv('/kaggle/input/coronahack-chest-xraydataset/Chest_xray_Corona_dataset_Summary.csv')\n",
        "\n",
        "metadata.sample(10)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "wI7lExar_3nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/MyDrive/KAGGLE UNDUHAN/CXR_CNN_RESNET.zip', 'r') as zipobj:\n",
        "    zipobj.extractall('CXRCVD')"
      ],
      "metadata": {
        "id": "h5iKZFNfAK9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = pd.read_csv('/content/CXRCVD/Chest_xray_Corona_Metadata.csv')\n",
        "summary = pd.read_csv('/content/CXRCVD/Chest_xray_Corona_dataset_Summary.csv')\n",
        "\n",
        "metadata.sample(10)"
      ],
      "metadata": {
        "id": "FebQm1tkAmQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBV0RmPI9Yz0"
      },
      "outputs": [],
      "source": [
        "train_data = metadata[metadata['Dataset_type'] == 'TRAIN']\n",
        "test_data = metadata[metadata['Dataset_type'] == 'TEST']\n",
        "assert train_data.shape[0] + test_data.shape[0] == metadata.shape[0]\n",
        "print(f\"Shape of train data : {train_data.shape}\")\n",
        "print(f\"Shape of test data : {test_data.shape}\")\n",
        "test_data.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUYP-L0b9Yz0"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "> Exploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns,to spot anomalies,to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.\n",
        "\n",
        "Source : [Exploratory Data Analysis](https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z76QbpxL9Yz1"
      },
      "outputs": [],
      "source": [
        "# Null value calculation\n",
        "print(f\"Count of null values in train :\\n{train_data.isnull().sum()}\")\n",
        "print(f\"Count of null values in test :\\n{test_data.isnull().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAIRv7gE9Yz1"
      },
      "outputs": [],
      "source": [
        "# Substitute null values with string unknown\n",
        "train_fill = train_data.fillna('unknown')\n",
        "test_fill = test_data.fillna('unknown')\n",
        "\n",
        "train_fill.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJXCKdOd9Yz2"
      },
      "outputs": [],
      "source": [
        "# Count plot for 3 attributes with unknown variable addition\n",
        "targets = ['Label', 'Label_2_Virus_category', 'Label_1_Virus_category']\n",
        "fig, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
        "sns.countplot(x=targets[0], data=train_fill, ax=ax[0, 0])\n",
        "sns.countplot(x=targets[1], data=train_fill, ax=ax[0, 1])\n",
        "sns.countplot(x=targets[2], data=train_fill, ax=ax[1, 0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsa8u3Ud9Yz3"
      },
      "outputs": [],
      "source": [
        "# Pie chart representation of Label_2_Virus_category values\n",
        "\n",
        "colors = ['#ff5733', '#33ff57']\n",
        "explode = [0.02, 0.02]\n",
        "\n",
        "values = ['unknown', 'other']\n",
        "percentages = [100 * (train_fill[train_fill[targets[1]] == 'unknown'].shape[0]) / train_fill.shape[0],\n",
        "              100 * (train_fill[train_fill[targets[1]] != 'unknown'].shape[0]) / train_fill.shape[0]]\n",
        "\n",
        "fig1, ax1 = plt.subplots(figsize=(7, 7))\n",
        "\n",
        "plt.pie(percentages, colors=colors, labels=values,\n",
        "        autopct='%1.1f%%', startangle=0, explode=explode)\n",
        "fig = plt.gcf()\n",
        "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
        "fig.gca().add_artist(centre_circle)\n",
        "\n",
        "ax1.axis('equal')\n",
        "plt.tight_layout()\n",
        "plt.title('Percentage of \"unknown\" values present in Label_2_Virus_category')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pW_aP95t9Yz4"
      },
      "outputs": [],
      "source": [
        "# Count plot for 3 target variables without filling unknown variable\n",
        "fig, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
        "sns.countplot(x=targets[0], data=train_data, ax=ax[0, 0])\n",
        "sns.countplot(x=targets[1], data=train_data, ax=ax[0, 1])\n",
        "sns.countplot(x=targets[2], data=train_data, ax=ax[1, 0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wLYfPPv9Yz4"
      },
      "outputs": [],
      "source": [
        "print(f\"Label = Normal Cases : {train_data[train_data['Label'] == 'Normal'].shape[0]}\")\n",
        "print(f\"\"\"Label = Pnemonia + Label_2_Virus_category = COVID-19 cases : {train_data[(train_data['Label'] == 'Pnemonia')\n",
        "      & (train_data['Label_2_Virus_category'] == 'COVID-19')].shape[0]}\"\"\")\n",
        "print(f\"\"\"Label = Normal + Label_2_Virus_category = COVID-19 cases : {train_data[(train_data['Label'] == 'Normal')\n",
        "      & (train_data['Label_2_Virus_category'] == 'COVID-19')].shape[0]}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxazQZol9Yz5"
      },
      "source": [
        "### Inference from count plots and Pie chart\n",
        "\n",
        "- All COVID-19 patients are classified with attribute Label as Pnemonia. None of them is classified as normal. \n",
        "- In target \"Label_2_Virus_category\", \"unknown\" value is associated with majority of images\n",
        "- Unknown values consist of 98.7 % of total cases while COVID-19 value consist of less than 1.3 % of total cases.\n",
        "- Even if we train a model to classify Label_2_virus_category with 98.7 % accuracy, it will be highly inefficient in detecting true positive COVID-19 cases.\n",
        "- Thus we are going to construct a model which differentiates between (Normal) and (Pnemonia + COVID-19) Cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpN4ue4N9Yz5"
      },
      "source": [
        "### Analysis of Image files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_xYiyT99Yz6"
      },
      "outputs": [],
      "source": [
        "TEST_FOLDER = '/content/CXRCVD/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'\n",
        "TRAIN_FOLDER = '/content/CXRCVD/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n",
        "\n",
        "assert os.path.isdir(TEST_FOLDER) == True\n",
        "assert os.path.isdir(TRAIN_FOLDER) == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifWSdxl09Yz6"
      },
      "outputs": [],
      "source": [
        "sample_train_images = list(os.walk(TRAIN_FOLDER))[0][2][:8]\n",
        "sample_train_images = list(map(lambda x: os.path.join(TRAIN_FOLDER, x), sample_train_images))\n",
        "\n",
        "sample_test_images = list(os.walk(TEST_FOLDER))[0][2][:8]\n",
        "sample_test_images = list(map(lambda x: os.path.join(TEST_FOLDER, x), sample_test_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP6_j9va9Yz6"
      },
      "outputs": [],
      "source": [
        "# Plot sample training images\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "for iterator, filename in enumerate(sample_train_images):\n",
        "    image = Image.open(filename)\n",
        "    plt.subplot(4, 2, iterator+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWEQrvsj9Yz7"
      },
      "outputs": [],
      "source": [
        "# Plot sample testing images\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "for iterator, filename in enumerate(sample_test_images):\n",
        "    image = Image.open(filename)\n",
        "    plt.subplot(4, 2, iterator+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_So7Eup9Yz8"
      },
      "source": [
        "### Image Histograms\n",
        "\n",
        "> An image histogram is a type of histogram that acts as a graphical representation of the tonal distribution in a digital image. It plots the number of pixels for each tonal value. By looking at the histogram for a specific image a viewer will be able to judge the entire tonal distribution at a glance.\n",
        "\n",
        "Source : [Image histogram](https://en.wikipedia.org/wiki/Image_histogram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eks-13jH9Yz8"
      },
      "outputs": [],
      "source": [
        "# Plot b/w image histograms of Label_2_Virus_category type \"COVID-19\" patients \n",
        "fig, ax = plt.subplots(4, 2, figsize=(20, 20))\n",
        "\n",
        "covid19_type_file_paths = train_data[train_data['Label_2_Virus_category'] == 'COVID-19']['X_ray_image_name'].values\n",
        "sample_covid19_file_paths = covid19_type_file_paths[:4]\n",
        "sample_covid19_file_paths = list(map(lambda x: os.path.join(TRAIN_FOLDER, x), sample_covid19_file_paths))\n",
        "\n",
        "for row, file_path in enumerate(sample_covid19_file_paths):\n",
        "    image = plt.imread(file_path)\n",
        "    ax[row, 0].imshow(image)\n",
        "    ax[row, 1].hist(image.ravel(), 256, [0,256])\n",
        "    ax[row, 0].axis('off')\n",
        "    if row == 0:\n",
        "        ax[row, 0].set_title('Images')\n",
        "        ax[row, 1].set_title('Histograms')\n",
        "fig.suptitle('Label 2 Virus Category = COVID-19', size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP9AJgYx9Yz9"
      },
      "outputs": [],
      "source": [
        "# Plot b/w image histograms of Label type \"Normal\" patients \n",
        "fig, ax = plt.subplots(4, 2, figsize=(20, 20))\n",
        "\n",
        "other_type_file_paths = train_data[train_data['Label'] == 'Normal']['X_ray_image_name'].values\n",
        "sample_other_file_paths = other_type_file_paths[:4]\n",
        "sample_other_file_paths = list(map(lambda x: os.path.join(TRAIN_FOLDER, x), sample_other_file_paths))\n",
        "\n",
        "for row, file_path in enumerate(sample_other_file_paths):\n",
        "    image = plt.imread(file_path)\n",
        "    ax[row, 0].imshow(image)\n",
        "    ax[row, 1].hist(image.ravel(), 256, [0,256])\n",
        "    ax[row, 0].axis('off')\n",
        "    if row == 0:\n",
        "        ax[row, 0].set_title('Images')\n",
        "        ax[row, 1].set_title('Histograms')\n",
        "fig.suptitle('Label = Normal', size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGncxTab9Yz-"
      },
      "source": [
        "### Inference\n",
        "\n",
        "- From the sample images, seperated according to Label 2 Virus Category into COVID-19 and Other, we can infer the difference in image histograms\n",
        "- The sample histograms of images having target as COVID-19 are mostly left-skewed histograms.\n",
        "- The sample histograms of images which have Label value as Normal are mostly right skewed histograms (with exception of image 4)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhyIlk8b9Yz_"
      },
      "source": [
        "## Image Augumentation\n",
        "\n",
        "> Deep networks need large amount of training data to achieve good performance. To build a powerful image classifier using very little training data, image augmentation is usually required to boost the performance of deep networks. Image augmentation artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc\n",
        "\n",
        "Source : [Image Augumentation for Deep Learning](https://towardsdatascience.com/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2)\n",
        "\n",
        "- We will be using keras ImageDataGenerator's inbuilt image augumentation functionality for the process of image augumentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7We_7TY9Yz_"
      },
      "source": [
        "### Sort out the file names to be worked on\n",
        "\n",
        "- From EDA, we decided to remove files with Label_2_Virus_category as NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1qmCE-69Y0A"
      },
      "outputs": [],
      "source": [
        "# Generate the final train data from original train data with conditions refered from EDA inference\n",
        "final_train_data = train_data[(train_data['Label'] == 'Normal') | \n",
        "                              ((train_data['Label'] == 'Pnemonia') & (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n",
        "\n",
        "\n",
        "# Create a target attribute where value = positive if 'Pnemonia + COVID-19' or value = negative if 'Normal'\n",
        "final_train_data['target'] = ['negative' if holder == 'Normal' else 'positive' for holder in final_train_data['Label']]\n",
        "\n",
        "final_train_data = shuffle(final_train_data, random_state=1)\n",
        "\n",
        "final_validation_data = final_train_data.iloc[1000:, :]\n",
        "final_train_data = final_train_data.iloc[:1000, :]\n",
        "\n",
        "print(f\"Final train data shape : {final_train_data.shape}\")\n",
        "final_train_data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSX8Xvfs9Y0A"
      },
      "outputs": [],
      "source": [
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=90,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=[0.9, 1.25],\n",
        "    brightness_range=[0.5, 1.5]\n",
        ")\n",
        "\n",
        "test_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "train_generator = train_image_generator.flow_from_dataframe(\n",
        "    dataframe=final_train_data,\n",
        "    directory=TRAIN_FOLDER,\n",
        "    x_col='X_ray_image_name',\n",
        "    y_col='target',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=8,\n",
        "    seed=2020,\n",
        "    shuffle=True,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = train_image_generator.flow_from_dataframe(\n",
        "    dataframe=final_validation_data,\n",
        "    directory=TRAIN_FOLDER,\n",
        "    x_col='X_ray_image_name',\n",
        "    y_col='target',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=8,\n",
        "    seed=2020,\n",
        "    shuffle=True,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_image_generator.flow_from_dataframe(\n",
        "    dataframe=test_data,\n",
        "    directory=TEST_FOLDER,\n",
        "    x_col='X_ray_image_name',\n",
        "    target_size=(224, 224),\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    class_mode=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEY5LBYM9Y0B"
      },
      "source": [
        "## Base CNN model accuracy calculation\n",
        "\n",
        "- The given 69 images divided into 4 classes will be trained on a simple 3 convolution layers CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Puud6jlr9Y0B"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch):\n",
        "    if epoch < 5:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        print(f\"Learning rate reduced to {0.0001 * np.exp(0.5 * (5 - epoch))}\")\n",
        "        return 0.0001 * np.exp(0.5 * (5 - epoch))\n",
        "    \n",
        "custom_callback = LearningRateScheduler(scheduler)\n",
        "\n",
        "METRICS = [\n",
        "      TruePositives(name='tp'),\n",
        "      FalsePositives(name='fp'),\n",
        "      TrueNegatives(name='tn'),\n",
        "      FalseNegatives(name='fn'), \n",
        "      BinaryAccuracy(name='accuracy'),\n",
        "      Precision(name='precision'),\n",
        "      Recall(name='recall'),\n",
        "      AUC(name='auc'),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZyBLKJk9Y0B"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(64, (3, 3), input_shape=(224, 224, 3), activation='relu'),\n",
        "    MaxPooling2D((3, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((3, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((3, 3)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(), loss=binary_crossentropy,\n",
        "             metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd7hdJix9Y0C"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                   validation_data=validation_generator,\n",
        "                   epochs=20,\n",
        "                   callbacks=[custom_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUOegAix9Y0C"
      },
      "outputs": [],
      "source": [
        "model.save('covid19_xray_base_cnn_model.h5')\n",
        "ACCURACY_LIST.append(['Base CNN Model', history])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC5344FQ9Y0C"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
        "sns.lineplot(x=np.arange(1, 21), y=history.history.get('loss'), ax=ax[0, 0])\n",
        "sns.lineplot(x=np.arange(1, 21), y=history.history.get('auc'), ax=ax[0, 1])\n",
        "sns.lineplot(x=np.arange(1, 21), y=history.history.get('val_loss'), ax=ax[1, 0])\n",
        "sns.lineplot(x=np.arange(1, 21), y=history.history.get('val_auc'), ax=ax[1, 1])\n",
        "ax[0, 0].set_title('Training Loss vs Epochs')\n",
        "ax[0, 1].set_title('Training AUC vs Epochs')\n",
        "ax[1, 0].set_title('Validation Loss vs Epochs')\n",
        "ax[1, 1].set_title('Validation AUC vs Epochs')\n",
        "fig.suptitle('Base CNN model', size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awgT3V4Z9Y0D"
      },
      "source": [
        "### Inference from base CNN model accuracy and AUC\n",
        "- Base CNN model\n",
        "    - Train data accuracy = 95.4 %\n",
        "    - Validation data accuracy = 97 %\n",
        "\n",
        "\n",
        "- Possible reasons for stale accuracy on 20 epochs\n",
        "    - Highly imbalance target variables\n",
        "        - COVID-19 target value = positive rows have count as 58\n",
        "        - Normal target value = negative rows have count as 1342\n",
        "        - `100 * (1342 / 1400) ~ 95.86 %`\n",
        "        - Even if model classifies all the images as \"Normal\" label, it would achieve 95.86 % accuracy\n",
        "        \n",
        "- V5 Changes:\n",
        "    - A good measure for imbalanced dataset is Area Under the Curve(AUC)\n",
        "    - The metrics for the model changed to AUC in version 5\n",
        "    - Comparision of models will be done based on AUC score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goW7ZzOg9Y0D"
      },
      "source": [
        "## Base CNN model with lower imbalance in data\n",
        "\n",
        "- In this subsection, we try to remove 95.86 % imbalance present in the data\n",
        "- We will remove 4 / 5 th of the Normal labelled images while keeping the count of COVID-19 labelled images same\n",
        "- `1342 / 5 ~ 269; 269 / (269 + 58) ~ 82.26 % `\n",
        "- To compensate for less number of training images, we increase the number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgOgWOd-9Y0D"
      },
      "outputs": [],
      "source": [
        "balanced_data = train_data[(train_data['Label'] == 'Normal') | \n",
        "                              ((train_data['Label'] == 'Pnemonia') & (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n",
        "\n",
        "balanced_data['target'] = ['negative' if holder == 'Normal' else 'positive' for holder in balanced_data['Label']]\n",
        "\n",
        "balanced_data_subset_normal = balanced_data[balanced_data['target'] == 'negative']\n",
        "balanced_data_subset_covid = balanced_data[balanced_data['target'] == 'positive']\n",
        "balanced_data_frac_normal = balanced_data_subset_normal.sample(frac=(1/5))\n",
        "\n",
        "balanced_data_concat = pd.concat([balanced_data_frac_normal, balanced_data_subset_covid], axis=0)\n",
        "balanced_data_concat = shuffle(balanced_data_concat, random_state=0)\n",
        "balanced_data_train = balanced_data_concat[:240]\n",
        "balanced_data_validation = balanced_data_concat[240:]\n",
        "\n",
        "print(f\"Balanced train data shape {balanced_data_train.shape}\")\n",
        "print(f\"Balanced validation data shape {balanced_data_validation.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PNfg9h-9Y0E"
      },
      "outputs": [],
      "source": [
        "balanced_train_generator = train_image_generator.flow_from_dataframe(\n",
        "    dataframe=balanced_data_train,\n",
        "    directory=TRAIN_FOLDER,\n",
        "    x_col='X_ray_image_name',\n",
        "    y_col='target',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "balanced_validation_generator = train_image_generator.flow_from_dataframe(\n",
        "    dataframe=balanced_data_validation,\n",
        "    directory=TRAIN_FOLDER,\n",
        "    x_col='X_ray_image_name',\n",
        "    y_col='target',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hugRQ6Lm9Y0E"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      TruePositives(name='tp'),\n",
        "      FalsePositives(name='fp'),\n",
        "      TrueNegatives(name='tn'),\n",
        "      FalseNegatives(name='fn'), \n",
        "      BinaryAccuracy(name='accuracy'),\n",
        "      Precision(name='precision'),\n",
        "      Recall(name='recall'),\n",
        "      AUC(name='auc'),\n",
        "]\n",
        "\n",
        "balanced_model = Sequential([\n",
        "    Conv2D(64, (3, 3), input_shape=(224, 224, 3), activation='relu'),\n",
        "    MaxPooling2D((3, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((3, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((3, 3)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "balanced_model.compile(optimizer=Adam(), loss=binary_crossentropy,\n",
        "             metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoQh0DvV9Y0F"
      },
      "outputs": [],
      "source": [
        "balanced_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_M9PqBx9Y0F"
      },
      "outputs": [],
      "source": [
        "balanced_history = balanced_model.fit_generator(balanced_train_generator,\n",
        "                                               epochs=30,\n",
        "                                               validation_data=balanced_validation_generator,\n",
        "                                               callbacks=[custom_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voFoO-_e9Y0G"
      },
      "outputs": [],
      "source": [
        "balanced_model.save('covid19_xray_base_cnn_model_balanced.h5')\n",
        "ACCURACY_LIST.append(['Balanced Base Model', balanced_history])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBrv9pfz9Y0G"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
        "sns.lineplot(x=np.arange(1, 31), y=balanced_history.history.get('loss'), ax=ax[0, 0])\n",
        "sns.lineplot(x=np.arange(1, 31), y=balanced_history.history.get('auc'), ax=ax[0, 1])\n",
        "sns.lineplot(x=np.arange(1, 31), y=balanced_history.history.get('val_loss'), ax=ax[1, 0])\n",
        "sns.lineplot(x=np.arange(1, 31), y=balanced_history.history.get('val_auc'), ax=ax[1, 1])\n",
        "ax[0, 0].set_title('Training Loss vs Epochs')\n",
        "ax[0, 1].set_title('Training AUC vs Epochs')\n",
        "ax[1, 0].set_title('Validation Loss vs Epochs')\n",
        "ax[1, 1].set_title('Validation AUC vs Epochs')\n",
        "fig.suptitle('Balanced base CNN model', size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfSH62z-9Y0G"
      },
      "source": [
        "### Inferences\n",
        "\n",
        "- Reducing imbalances results in reduced training images\n",
        "- Accuracy reduced because of reduced training images\n",
        "- Validation accuracy still remains stale even on reducing number of \"Normal\" labelled images\n",
        "- V5 changes:\n",
        "    - A good measure for imbalanced dataset is Area Under the Curve(AUC)\n",
        "    - The metrics for the model changed to AUC in version 5\n",
        "    - Comparision of models will be done based on AUC score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5O5yPS89Y0G"
      },
      "source": [
        "## Training ResNet 50 on data\n",
        "\n",
        "[ResNet Introduction and Architecture](https://neurohive.io/en/popular-networks/resnet/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLH91sQM9Y0H"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      TruePositives(name='tp'),\n",
        "      FalsePositives(name='fp'),\n",
        "      TrueNegatives(name='tn'),\n",
        "      FalseNegatives(name='fn'), \n",
        "      BinaryAccuracy(name='accuracy'),\n",
        "      Precision(name='precision'),\n",
        "      Recall(name='recall'),\n",
        "      AUC(name='auc'),\n",
        "]\n",
        "\n",
        "def output_custom_model(prebuilt_model):\n",
        "    print(f\"Processing {prebuilt_model}\")\n",
        "    prebuilt = prebuilt_model(include_top=False,\n",
        "                            input_shape=(224, 224, 3),\n",
        "                            weights='imagenet')\n",
        "    output = prebuilt.output\n",
        "    output = GlobalMaxPooling2D()(output)\n",
        "    output = Dense(128, activation='relu')(output)\n",
        "    output = Dropout(0.2)(output)\n",
        "    output = Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "    model = Model(inputs=prebuilt.input, outputs=output)\n",
        "    model.compile(optimizer='sgd', loss=binary_crossentropy,\n",
        "              metrics=METRICS)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89t5jft39Y0H"
      },
      "outputs": [],
      "source": [
        "resnet_custom_model = output_custom_model(ResNet50)\n",
        "resnet_history = resnet_custom_model.fit_generator(train_generator,\n",
        "                                 epochs=20,\n",
        "                                 validation_data=validation_generator,\n",
        "                                 callbacks=[custom_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EfsFb-g9Y0H"
      },
      "outputs": [],
      "source": [
        "resnet_custom_model.save('covid19_xray_resnet_50.h5')\n",
        "ACCURACY_LIST.append(['ResNet 50', resnet_history])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eh9RIIzv9Y0I"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
        "sns.lineplot(x=np.arange(1, 21), y=resnet_history.history.get('loss'), ax=ax[0, 0])\n",
        "sns.lineplot(x=np.arange(1, 21), y=resnet_history.history.get('auc'), ax=ax[0, 1])\n",
        "sns.lineplot(x=np.arange(1, 21), y=resnet_history.history.get('val_loss'), ax=ax[1, 0])\n",
        "sns.lineplot(x=np.arange(1, 21), y=resnet_history.history.get('val_auc'), ax=ax[1, 1])\n",
        "ax[0, 0].set_title('Training Loss vs Epochs')\n",
        "ax[0, 1].set_title('Training AUC vs Epochs')\n",
        "ax[1, 0].set_title('Validation Loss vs Epochs')\n",
        "ax[1, 1].set_title('Validation AUC vs Epochs')\n",
        "fig.suptitle('ResNet 50 model', size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJN-MP7-9Y0I"
      },
      "source": [
        "### Inference\n",
        "\n",
        "- The effect of data imbalance is visible in validation accuracy measures\n",
        "- Training accuracy of ResNet 50 is almost equal to base CNN model\n",
        "- V5 Changes:\n",
        "    - A good measure for imbalanced dataset is Area Under the Curve(AUC)\n",
        "    - The metrics for the model changed to AUC in version 5\n",
        "    - Comparision of models will be done based on AUC score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XF7w-8S9Y0I"
      },
      "source": [
        "## Training EfficientNet B4 on data\n",
        "\n",
        "[EfficientNet Arxiv Paper](https://arxiv.org/abs/1905.11946)\n",
        "\n",
        "- Reduced batch-size of data generators due to ResourceExhaustionError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-1ie2KK9Y0I"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      TruePositives(name='tp'),\n",
        "      FalsePositives(name='fp'),\n",
        "      TrueNegatives(name='tn'),\n",
        "      FalseNegatives(name='fn'), \n",
        "      BinaryAccuracy(name='accuracy'),\n",
        "      Precision(name='precision'),\n",
        "      Recall(name='recall'),\n",
        "      AUC(name='auc'),\n",
        "]\n",
        "\n",
        "efficient_net_custom_model = output_custom_model(EfficientNetB4)\n",
        "efficient_net_history = efficient_net_custom_model.fit_generator(train_generator,\n",
        "                                 epochs=20,\n",
        "                                 validation_data=validation_generator,\n",
        "                                 callbacks=[custom_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex7LmeTg9Y0J"
      },
      "outputs": [],
      "source": [
        "efficient_net_custom_model.save('covid19_xray_efficient_net_B4.h5')\n",
        "ACCURACY_LIST.append(['EfficientNet B4', efficient_net_history])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wApTpqna9Y0J"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
        "sns.lineplot(x=np.arange(1, 21), y=efficient_net_history.history.get('loss'), ax=ax[0, 0])\n",
        "sns.lineplot(x=np.arange(1, 21), y=efficient_net_history.history.get('auc'), ax=ax[0, 1])\n",
        "sns.lineplot(x=np.arange(1, 21), y=efficient_net_history.history.get('val_loss'), ax=ax[1, 0])\n",
        "sns.lineplot(x=np.arange(1, 21), y=efficient_net_history.history.get('val_auc'), ax=ax[1, 1])\n",
        "ax[0, 0].set_title('Training Loss vs Epochs')\n",
        "ax[0, 1].set_title('Training AUC vs Epochs')\n",
        "ax[1, 0].set_title('Validation Loss vs Epochs')\n",
        "ax[1, 1].set_title('Validation AUC vs Epochs')\n",
        "fig.suptitle('EfficientNet B4 model', size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyZ6OUKG9Y0J"
      },
      "source": [
        "## Binary Accuracy and AUC score comparision\n",
        "\n",
        "- As the data is imbalanced, more concentration will be given on AUC score comparision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFI2mJU69Y0K"
      },
      "outputs": [],
      "source": [
        "ACCURACY_LIST = np.array(ACCURACY_LIST)\n",
        "model_names = ACCURACY_LIST[:, 0]\n",
        "histories = ACCURACY_LIST[:, 1]\n",
        "\n",
        "fig, ax = plt.subplots(2, 2, figsize=(20, 20))\n",
        "sns.barplot(x=model_names, y=list(map(lambda x: x.history.get('auc')[-1], histories)), ax=ax[0, 0], palette='Spectral')\n",
        "sns.barplot(x=model_names, y=list(map(lambda x: x.history.get('val_auc')[-1], histories)), ax=ax[0, 1], palette='gist_yarg')\n",
        "sns.barplot(x=model_names, y=list(map(lambda x: x.history.get('accuracy')[-1], histories)), ax=ax[1, 0], palette='rocket')\n",
        "sns.barplot(x=model_names, y=list(map(lambda x: x.history.get('val_accuracy')[-1], histories)), ax=ax[1, 1], palette='ocean_r')\n",
        "ax[0, 0].set_title('Model Training AUC scores')\n",
        "ax[0, 1].set_title('Model Validation AUC scores')\n",
        "ax[1, 0].set_title('Model Training Accuracies')\n",
        "ax[1, 1].set_title('Model Validation Accuracies')\n",
        "fig.suptitle('Model Comparisions')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUDQdf5k9Y0K"
      },
      "source": [
        "## TP, FP, TN, FN model comparisions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JWiWWaM9Y0K"
      },
      "outputs": [],
      "source": [
        "metric_dataframe = pd.DataFrame({\n",
        "    'Model Names': model_names,\n",
        "    'True Positives': list(map(lambda x: x.history.get('tp')[-1], histories)),\n",
        "    'False Positives': list(map(lambda x: x.history.get('fp')[-1], histories)),\n",
        "    'True Negatives': list(map(lambda x: x.history.get('tn')[-1], histories)),\n",
        "    'False Negatives': list(map(lambda x: x.history.get('fn')[-1], histories))\n",
        "})\n",
        "fig, ax = plt.subplots(2, 2, figsize=(20, 20))\n",
        "sns.barplot(x='Model Names', y='True Positives', data=metric_dataframe, ax=ax[0, 0], palette='BrBG')\n",
        "sns.barplot(x='Model Names', y='False Positives', data=metric_dataframe, ax=ax[0, 1], palette='icefire_r')\n",
        "sns.barplot(x='Model Names', y='True Negatives', data=metric_dataframe, ax=ax[1, 0], palette='PuBu_r')\n",
        "sns.barplot(x='Model Names', y='False Negatives', data=metric_dataframe, ax=ax[1, 1], palette='YlOrBr')\n",
        "ax[0, 0].set_title('True Positives of Models')\n",
        "ax[0, 1].set_title('False Positives of Models')\n",
        "ax[1, 0].set_title('True Negatives of Models')\n",
        "ax[1, 1].set_title('False Negatives of Models')\n",
        "fig.suptitle('Confusion Matrix comparision of Models', size=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZJ3SatJ9Y0L"
      },
      "source": [
        "### Inference from metric comparisions\n",
        "\n",
        "- ResNet 50 has the most AUC score out of all the models\n",
        "- In our experiment, it is higly important for a model to correctly predict COVID-19 patient, thus it should have high True Positive score and low False Negative score\n",
        "- ResNet 50 has the highest True Positive score and lowest False Negative score\n",
        "- From the metric comparisions, ResNet 50 model performs better than other models in the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ngisfbe19Y0L"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}